{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local) created by __init__ at <ipython-input-4-4154298628d2>:3 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4154298628d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'local'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\spark-env\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\spark-env\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    330\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[1;32m--> 332\u001b[1;33m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[0;32m    333\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local) created by __init__ at <ipython-input-4-4154298628d2>:3 "
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "df = spark.read.option('header','true')\\\n",
    ".option('index','false')\\\n",
    ".option('inferSchema','true')\\\n",
    ".csv(\"file:///F:\\MiNI IAD\\Sem 1\\Big Data\\GitHub-Repos-BigData\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.__class__\n",
    "df = df.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(diskUsage=2.531667508315967, forkCount=0, squashMergeAllowed=0, isArchived=0, isFork=0, Ruby=0.8642358417377812, assign_=3.0, stargazer_=2.0, milestone=0.0, Python=0.0, Shell=0.0, HTML=0.0, JavaScript=0.0, Makefile=0.0, C++=0.0, C=0.0, Java=0.0, CSS=0.0, RepoAge=3057, RepoLife=283, label=0, languageCounter=2, popularLanguageCounter=1, hasLanguage=0, description_len=44, has_description=0, has_issue=0, stargazer_non_zero=0, has_milestone=0, has_release=0, contributed=0)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[diskUsage: double, forkCount: int, squashMergeAllowed: int, isArchived: int, isFork: int, Ruby: double, assign_: double, stargazer_: double, milestone: double, Python: double, Shell: double, HTML: double, JavaScript: double, Makefile: double, C++: double, C: double, Java: double, CSS: double, RepoAge: int, RepoLife: int, label: int, languageCounter: int, popularLanguageCounter: int, hasLanguage: int, description_len: int, has_description: int, has_issue: int, stargazer_non_zero: int, has_milestone: int, has_release: int, contributed: int]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = df.columns\n",
    "features.remove(\"label\")\n",
    "data = df.select(col(\"label\"), *features)\n",
    "(training, test) = data.randomSplit([.7, .3])\n",
    "vectorAssembler = VectorAssembler(inputCols=features, outputCol=\"unscaled_features\")\n",
    "standardScaler = StandardScaler(inputCol=\"unscaled_features\", outputCol=\"features\")\n",
    "lr = LinearRegression(maxIter=10, regParam=.01)\n",
    "\n",
    "stages = [vectorAssembler, standardScaler, lr]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "model = pipeline.fit(training)\n",
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.255\n",
      "MSE: 0.065\n",
      "MAE: 0.163\n",
      "r2: 0.357\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "eval = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = eval.evaluate(prediction)\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = eval.evaluate(prediction, {eval.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = eval.evaluate(prediction, {eval.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = eval.evaluate(prediction, {eval.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-33f8c64e6fec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "row['features'].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.06684491978609626\n",
      "Learned classification tree model:\n",
      "DecisionTreeModel classifier of depth 5 with 39 nodes\n",
      "  If (feature 18 <= 121.0)\n",
      "   If (feature 13 <= 2.9212176085419155E-5)\n",
      "    If (feature 23 <= 49.5)\n",
      "     If (feature 10 <= 0.013836678149114202)\n",
      "      If (feature 20 <= 7.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 20 > 7.5)\n",
      "       Predict: 0.0\n",
      "     Else (feature 10 > 0.013836678149114202)\n",
      "      If (feature 0 <= 1.706995065329957)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 1.706995065329957)\n",
      "       Predict: 0.0\n",
      "    Else (feature 23 > 49.5)\n",
      "     If (feature 21 <= 1.5)\n",
      "      If (feature 19 <= 5.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 19 > 5.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 21 > 1.5)\n",
      "      Predict: 1.0\n",
      "   Else (feature 13 > 2.9212176085419155E-5)\n",
      "    If (feature 12 <= 2.0848018639055244E-6)\n",
      "     If (feature 19 <= 5.5)\n",
      "      If (feature 5 <= 8.952257258627138E-6)\n",
      "       Predict: 0.0\n",
      "      Else (feature 5 > 8.952257258627138E-6)\n",
      "       Predict: 1.0\n",
      "     Else (feature 19 > 5.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 12 > 2.0848018639055244E-6)\n",
      "     Predict: 1.0\n",
      "  Else (feature 18 > 121.0)\n",
      "   If (feature 29 <= 0.5)\n",
      "    If (feature 19 <= 454.5)\n",
      "     If (feature 18 <= 438.5)\n",
      "      If (feature 19 <= 84.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 19 > 84.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 18 > 438.5)\n",
      "      Predict: 0.0\n",
      "    Else (feature 19 > 454.5)\n",
      "     If (feature 18 <= 907.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 18 > 907.5)\n",
      "      Predict: 0.0\n",
      "   Else (feature 29 > 0.5)\n",
      "    If (feature 19 <= 127.5)\n",
      "     If (feature 21 <= 4.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 21 > 4.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 19 > 127.5)\n",
      "     If (feature 0 <= 1.706995065329957)\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 > 1.706995065329957)\n",
      "      Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Load and parse the data file into an RDD of LabeledPoint.\n",
    "# data = MLUtils.loadLibSVMFile(sc, \"file:///F:\\MiNI IAD\\Sem 1\\Big Data\\GitHub-Repos-BigData\\data.csv\",multiclass=True, numFeatures=31).collect()\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "def parse_points(df):\n",
    "    \"\"\"Converts a DataFrame of comma separated unicode strings into a DataFrame of `LabeledPoints`.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame where each row is a comma separated unicode string. The first element in the string\n",
    "            is the label and the remaining elements are the features.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Each row is converted into a `LabeledPoint`, which consists of a label and\n",
    "            features. To convert an RDD to a DataFrame, simply call toDF().\n",
    "    \"\"\"\n",
    "    token = df.split(\",\")\n",
    "#     print(token.__class__)\n",
    "    label = float(token[0])\n",
    "    features = token[1:]\n",
    "    return LabeledPoint(label,features)\n",
    "\n",
    "\n",
    "\n",
    "raw_data_df =  sc.textFile(\"file:///F:\\MiNI IAD\\Sem 1\\Big Data\\GitHub-Repos-BigData\\data.csv\")\n",
    "\n",
    "features = raw_data_df.take(1)\n",
    "tagsheader = raw_data_df.first()\n",
    "header = sc.parallelize([tagsheader])\n",
    "raw_data_df = raw_data_df.subtract(header)\n",
    "\n",
    "parsed_points_df = raw_data_df.map(lambda x: parse_points(x))\n",
    "\n",
    "first_point_features = parsed_points_df.first().features\n",
    "first_point_label = parsed_points_df.first().label\n",
    "\n",
    "(trainingData, testData) = parsed_points_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "model = DecisionTree.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},impurity='gini', maxDepth=5, maxBins=32)\n",
    "\n",
    "# # Evaluate model on test instances and compute test error\n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification tree model:')\n",
    "print(model.toDebugString())\n",
    "\n",
    "# # Save and load model\n",
    "model.save(sc, \"../myDecisionTreeClassificationModel\")\n",
    "sameModel = DecisionTreeModel.load(sc, \"../myDecisionTreeClassificationModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spark_tree_plotting'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-ed18f2801bae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspark_tree_plotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m tree_plot = plot_tree(model,\n\u001b[0;32m      4\u001b[0m                       \u001b[0mfeatureNames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                       categoryNames={\"wilderness_area_indexed\":string_indexer_wilderness_model.labels,\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spark_tree_plotting'"
     ]
    }
   ],
   "source": [
    "from spark_tree_plotting import plot_tree\n",
    "\n",
    "tree_plot = plot_tree(model,\n",
    "                      featureNames=features,\n",
    "                      categoryNames={\"wilderness_area_indexed\":string_indexer_wilderness_model.labels,\n",
    "                                     \"soil_type_indexed\":string_indexer_soil_model.labels},\n",
    "                      classNames=string_indexer_cover_model.labels,\n",
    "                      filled=True,          # With color!\n",
    "                      roundedCorners=True,  # Rounded corners in the nodes\n",
    "                      roundLeaves=True      # Leaves will be ellipses instead of rectangles\n",
    "                     )\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(tree_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
